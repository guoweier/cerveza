import os, re
import pandas as pd
from Bio import SeqIO
shell.executable("bash")

configfile: "config.yaml"

units = pd.read_csv(config["units"], index_col=["sample", "unit"], dtype=str, sep = "\t")
units.index = units.index.set_levels([i.astype(str) for i in units.index.levels])

samples = {}
for i in units.index.levels[0]:
    samples[i] = ["data/clipOverlap/{}-{}.bam".format(i, j) for j in units.loc[i].index]

def is_single_end(sample,unit):
    return pd.isnull(units.loc[(sample, unit), "fq2"])

def get_fastq(wildcards):
    return "data/reads/"+units.loc[(wildcards.sample, wildcards.unit), ["fq1", "fq2"]].dropna()

def get_trimmed(wildcards):
    if not is_single_end(**wildcards):
        return expand("data/trimmed/{sample}-{unit}-{group}.fastq.gz",
            group=[1,2], **wildcards)
    return "data/trimmed/{sample}-{unit}.fastq.gz".format(**wildcards)
    
def get_intervals(ref, main_size, backup_size=3000):
    
    """
    Identify natural breaks in genome assembly for scatter-gather variant calling
    
    Works when the genome assembly is highly fragmented, will crash due to memory overuse
    with highly contiguous long read assemblies.
    """
    
    intervals = []

    with open(ref, 'r') as handle:
        for record in SeqIO.parse(handle, "fasta"):
            
            if record.id not in config["good_chroms"]:
                continue
            
            print("Finding gaps on {}".format(record.id))
            
            start = 0
            tmp_int = []
            s=record.seq
            scaff_regex = "N"*int(main_size)+"+"
            intervals += chunk_by_gap(record, main_size, backup_size)
        
    o = open(config["intervals"], 'w')
    o.write('\n'.join(intervals)+'\n')
    return intervals
    
def chunk_by_gap(record, main_size, backup_size=3000, hardcut_size=1e6):

    """
    Identify gaps in one SeqIO fasta entry
    If dividing by gaps of main_size fails, attempt to divide by backup_size gaps
    """
    
    start = 0
    tmp_int = []
    scaff_regex = "N{" + str(int(main_size)) + ",}"
    # print(scaff_regex)
    
    for match in re.finditer(scaff_regex, str(record.seq)):
        tmp_int.append("{}\t{}\t{}".format(record.id, start, match.start()))
        start = match.end()
    
    # Was it divided up? If not, try a smaller gap size
    if start == 0:
        backup_regex = "N{" + str(int(backup_size)) + ",}"
        for match in re.finditer(backup_regex, str(record.seq)):
            tmp_int.append("{}\t{}\t{}".format(record.id, start, match.start()))
            start = match.end()
    
    # Handle last interval if fasta doesn't end with Ns
    if start != 0 and start < len(record):
        tmp_int.append("{}\t{}\t{}".format(record.id, start, len(record)))
        
        
    # Handle last interval if fasta ends with Ns
    elif start > len(record):
        fix_start = tmp_int[-1].split('\t')[1]
        tmp_int[-1] = ("{}\t{}\t{}".format(record.id, fix_start, len(record)))
        
    # if still haven't made a cut, do a hard cut
    elif start == 0:
        while start < len(record)-hardcut_size:
            tmp_int.append("{}\t{}\t{}".format(record.id, int(start), int(start)+int(hardcut_size)))
            start += hardcut_size
        tmp_int.append("{}\t{}\t{}".format(record.id, int(start), len(record)))
    
    return tmp_int

# manually identify natural breaks in genome assembly if program doesn't find user-supplied variant calling intervals
# note, this is not optimal for highly contiguous genome assemblies
try:
    ifh = open(config["intervals"], 'r')
    intervals = []
    for line in ifh:
        intervals.append(line.rstrip())
except FileNotFoundError:
    intervals = get_intervals(config["genome"], 5e4)

rule all:
    input:
        re.sub("(\.fasta$|\.fa$)", ".genome", config["genome"]),
        re.sub("(\.fasta$|\.fa$)", "100k_windows.bed", config["genome"]),
        # ["data/realigned/{}.bam".format(x) for x in units.index.levels[0]],
        ["data/merged/{}.bam".format(x) for x in units.index.levels[0]],
        ["data/depths/{}_q20_depth.bed".format(x) for x in units.index.levels[0]],
        ["data/readcounts/{}.bed".format(x) for x in units.index.levels[0]],
        "data/calls/all-calls.vcf"

include: "rules/bedtools_genome_windows.rules"
include: "rules/bedtools_coverage.rules"
include: "rules/merge_vcfs.rules"
include: "rules/freebayes_interval.rules"
include: "rules/samtools_q20_depth.rules"
include: "rules/samtools_q0_depth.rules"
include: "rules/realign_indels.rules" # testing placement at this point in the workflow, rule rewritten
include: "rules/realigner_target_creator.rules" # testing placement at this point in the workflow, rule rewritten
include: "rules/samtools_index_pe.rules" # change for later indel realign
include: "rules/samtools_merge.rules" # change for later indel realign
include: "rules/clip_overlap.rules" # changed for later indel realign
include: "rules/filter_good_pairs.rules"
include: "rules/mark_duplicates.rules"
include: "rules/align.rules"
include: "rules/cutadapt_pe.rules"
include: "rules/cutadapt.rules"
include: "rules/fastqc.rules"
